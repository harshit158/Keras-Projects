{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "max_len = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 70), (25000, 70))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 8, input_length=max_len))\n",
    "\n",
    "model.add(Flatten())\n",
    "'''Since we are using feedforward dense network, the outputs of Embedding layer have to be flattened\n",
    "to bring into the form (batch_size, features)'''\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 70, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 560)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 561       \n",
      "=================================================================\n",
      "Total params: 80,561\n",
      "Trainable params: 80,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.1452 - acc: 0.9501 - val_loss: 0.4027 - val_acc: 0.8364\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.1298 - acc: 0.9566 - val_loss: 0.4157 - val_acc: 0.8332\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.1154 - acc: 0.9633 - val_loss: 0.4292 - val_acc: 0.8300\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.1023 - acc: 0.9685 - val_loss: 0.4429 - val_acc: 0.8292\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.0900 - acc: 0.9721 - val_loss: 0.4575 - val_acc: 0.8262\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.0789 - acc: 0.9774 - val_loss: 0.4727 - val_acc: 0.8240\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.0689 - acc: 0.9800 - val_loss: 0.4903 - val_acc: 0.8206\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.0596 - acc: 0.9834 - val_loss: 0.5088 - val_acc: 0.8176\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.0515 - acc: 0.9865 - val_loss: 0.5270 - val_acc: 0.8148\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.0443 - acc: 0.9886 - val_loss: 0.5463 - val_acc: 0.8124\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                     epochs=10, \n",
    "                     batch_size=32,\n",
    "                     validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 324,160\n",
      "Trainable params: 324,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 32)                8320      \n",
      "=================================================================\n",
      "Total params: 328,320\n",
      "Trainable params: 328,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, TimeDistributed\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(LSTM(32))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
